{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details. You can download the required DB from the shared dropbox or from blackboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ebbi_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "\n",
    "from string import punctuation\n",
    "import re\n",
    "import os\n",
    "import html\n",
    "\n",
    "\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "#from text_functions_solutions import clean_tokenize, get_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some punctuation variations\n",
    "punctuation = set(punctuation) # speeds up comparison\n",
    "tw_punct = punctuation - {\"#\"}\n",
    "\n",
    "# Stopwords\n",
    "sw = set(stopwords)\n",
    "\n",
    "# Two useful regex\n",
    "whitespace_pattern = re.compile(r\"\\s+\")\n",
    "hashtag_pattern = re.compile(r\"^#[0-9a-zA-Z]+\")\n",
    "\n",
    "def descriptive_stats(tokens, num_tokens = 5, verbose=True) :\n",
    "    counter = Counter()\n",
    "    tokens.map(counter.update)\n",
    "    freq_df = pd.DataFrame.from_dict(counter, orient='index', columns=['freq'])\n",
    "    counter_df = pd.DataFrame.from_dict(counter, orient='index').reset_index()\n",
    "    num_tokens = sum(freq_df['freq'])\n",
    "    num_unique_tokens = freq_df.shape[0]\n",
    "    lexical_diversity = num_unique_tokens / num_tokens\n",
    "    num_characters = sum((counter_df['index'].str.len()) * counter_df[0])\n",
    "\n",
    "    if verbose :\n",
    "        print(f\"There are {num_tokens} tokens in the data.\")\n",
    "        print(f\"There are {num_unique_tokens} unique tokens in the data.\")\n",
    "        print(f\"There are {num_characters} characters in the data.\")\n",
    "        print(f\"The lexical diversity is {lexical_diversity:.3f} in the data.\")\n",
    "        print(f\"The top 5 most common words are\")\n",
    "        print(counter.most_common(5))\n",
    "\n",
    "    return(0)\n",
    "\n",
    "def remove_stop(tokens) :\n",
    "    return [t for t in tokens if t.lower() not in stopwords]\n",
    " \n",
    "def remove_punctuation(text, punct_set=tw_punct) : \n",
    "    return(\"\".join([ch for ch in text if ch not in punct_set]))\n",
    "\n",
    "def tokenize(text):\n",
    "    return re.findall(r'\\S+', text)\n",
    "\n",
    "def prepare(text, pipeline) : \n",
    "    tokens = str(text)\n",
    "    \n",
    "    for transform in pipeline : \n",
    "        tokens = transform(tokens)\n",
    "        \n",
    "    return(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    # convert html escapes like &amp; to characters.\n",
    "    text = html.unescape(text)\n",
    "    # tags like <tab>\n",
    "    text = re.sub(r'<[^<>]*>', ' ', text)\n",
    "    # markdown URLs like [Some text](https://....)\n",
    "    text = re.sub(r'\\[([^\\[\\]]*)\\]\\([^\\(\\)]*\\)', r'\\1', text)\n",
    "    # text or code in brackets like [0]\n",
    "    text = re.sub(r'\\[[^\\[\\]]*\\]', ' ', text)\n",
    "    # standalone sequences of specials, matches &# but not #cool\n",
    "    text = re.sub(r'(?:^|\\s)[&#<>{}\\[\\]+|\\\\:-]{1,}(?:\\s|$)', ' ', text) \n",
    "    # standalone sequences of hyphens like --- or ==\n",
    "    text = re.sub(r'(?:^|\\s)[\\-=\\+]{2,}(?:\\s|$)', ' ', text)\n",
    "    # sequences of white spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipeline = [str.lower, remove_punctuation, tokenize, remove_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text \n",
    "for each party and prepare it for use in Naive Bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_data = []\n",
    "\n",
    "# fill this list up with items that are themselves lists. The \n",
    "# first element in the sublist should be the cleaned and tokenized\n",
    "# text in a single string. The second element should be the party. \n",
    "\n",
    "query_results = convention_cur.execute(\n",
    "    \"SELECT text, party FROM conventions;\")\n",
    "\n",
    "convention_table = []\n",
    "\n",
    "for row in query_results :\n",
    "    # store the results in convention_data\n",
    "    text, party = row\n",
    "    convention_table.append((text, party))\n",
    "\n",
    "convention_df = pd.DataFrame(convention_table, columns = [\"text\", \"party\"])\n",
    "\n",
    "convention_df[\"tokens\"] = convention_df['text'].apply(\n",
    "    prepare, pipeline = my_pipeline)\n",
    "convention_df[\"cleantext\"] = convention_df[\"text\"].apply(clean)\n",
    "convention_df[\"cleantext\"] = convention_df[\"cleantext\"].apply(str.lower)\n",
    "convention_df[\"cleantext\"] = convention_df[\"cleantext\"].apply(\n",
    "    remove_punctuation)\n",
    "\n",
    "#convention_df['text'] = tokens\n",
    "\n",
    "convention_data = convention_df[[\"cleantext\", \"party\"]].values.tolist()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['mccain passed his vote with a thumbs down', 'Democratic'],\n",
       " ['we need to change the paradigm and that happens here with us',\n",
       "  'Democratic'],\n",
       " ['at the end of the day i think we’re all very happy we had that meeting',\n",
       "  'Democratic'],\n",
       " ['and if you give him your cell phone number… ashley biden  015143  he’s going to call it',\n",
       "  'Democratic'],\n",
       " ['questions about money he made from foreign business dealings while his father was vice president',\n",
       "  'Republican'],\n",
       " [' relatives as a first american and citizen of the standing rock sioux tribe i welcome you to the paha sapa the black hills the site of my creation story and home to the oceti sakowin the great sioux nation we often say  we are all related our next president must lead by this philosophy for the betterment of our next seven generations we cast 3 votes for senator bernie sanders and 17 votes for our next president joe biden',\n",
       "  'Democratic'],\n",
       " ['good evening i’m sally yates speaking at a political convention is something i never expected to be doing but the future of our democracy is at stake i’m here in my hometown of atlanta where as a young lawyer i joined our nation’s justice department for nearly 30 years through democratic and republican administrations i worked alongside my doj colleagues to advance our nation’s promise of equal justice',\n",
       "  'Democratic'],\n",
       " ['let’s give parents the peace of mind that their kids are safe and are being set up for success',\n",
       "  'Democratic'],\n",
       " ['focused on the wellbeing of children social media use and opioid abuse',\n",
       "  'Republican'],\n",
       " ['the plan was working everybody had a job making money spending money boom bang boom we’re good',\n",
       "  'Republican']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5\n",
      "we have 2510 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in convention_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}\")\n",
    "print(f\"we have {len(feature_words)} as features in the model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_df[\"tokens\"] = convention_df[\"cleantext\"].apply(\n",
    "    prepare,pipeline=my_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw) :\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "       feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * fw: the *feature words* that we're considering. A word \n",
    "            in `text` must be in fw in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `fw`. \n",
    "            Words are only counted once. \n",
    "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Your code here\n",
    "    \n",
    "    ret_dict = dict()\n",
    "    \n",
    "    tokens = tokenize(text)\n",
    "    for token in tokens:\n",
    "        if token in fw :\n",
    "            ret_dict[token] = True\n",
    "            \n",
    "    return(ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'donald': True, 'is': True, 'the': True, 'president': True}\n",
      "{'some': True, 'people': True, 'in': True, 'america': True, 'are': True, 'citizens': True}\n"
     ]
    }
   ],
   "source": [
    "assert(len(feature_words)>0)\n",
    "print(conv_features(\"donald is the president\",feature_words))\n",
    "#=={'donald':True,'president':True})\n",
    "print(conv_features(\"some people in america are citizens\",feature_words))\n",
    "#=={'people':True,'america':True,\"citizens\":True})\n",
    "#All result in true - the data is structured differently so ASSERT does not work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) \n",
    "               for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.444\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   china = True           Republ : Democr =     25.8 : 1.0\n",
      "                   votes = True           Democr : Republ =     23.8 : 1.0\n",
      "             enforcement = True           Republ : Democr =     21.5 : 1.0\n",
      "                 destroy = True           Republ : Democr =     19.2 : 1.0\n",
      "                freedoms = True           Republ : Democr =     18.2 : 1.0\n",
      "                 climate = True           Democr : Republ =     17.8 : 1.0\n",
      "                supports = True           Republ : Democr =     17.1 : 1.0\n",
      "                   crime = True           Republ : Democr =     16.1 : 1.0\n",
      "                   media = True           Republ : Democr =     14.9 : 1.0\n",
      "                 beliefs = True           Republ : Democr =     13.0 : 1.0\n",
      "               countries = True           Republ : Democr =     13.0 : 1.0\n",
      "                 defense = True           Republ : Democr =     13.0 : 1.0\n",
      "                    isis = True           Republ : Democr =     13.0 : 1.0\n",
      "                 liberal = True           Republ : Democr =     13.0 : 1.0\n",
      "                religion = True           Republ : Democr =     13.0 : 1.0\n",
      "                   trade = True           Republ : Democr =     12.7 : 1.0\n",
      "                    flag = True           Republ : Democr =     12.1 : 1.0\n",
      "               greatness = True           Republ : Democr =     12.1 : 1.0\n",
      "                 abraham = True           Republ : Democr =     11.9 : 1.0\n",
      "                  defund = True           Republ : Democr =     11.9 : 1.0\n",
      "                    drug = True           Republ : Democr =     10.9 : 1.0\n",
      "              department = True           Republ : Democr =     10.9 : 1.0\n",
      "               destroyed = True           Republ : Democr =     10.9 : 1.0\n",
      "                   enemy = True           Republ : Democr =     10.9 : 1.0\n",
      "               amendment = True           Republ : Democr =     10.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "The analysis of the classifier reveals intriguing patterns. Republicans often emphasize patriotic buzzwords like \"destroy,\" \"freedoms,\" and \"flag,\" aiming to evoke national pride and potentially nationalism among their supporters. The repeated mentions of \"enemy,\" \"isis,\" and \"China\" suggest a divisive tone. In contrast, Democrats focus on broader issues like climate and voting, possibly reflecting their emphasis on environmental concerns and mobilizing voters. The distinction in language use underscores the parties' different priorities and communication strategies during the critical period of 2020, particularly regarding the global pandemic and geopolitical tensions.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsdf = pd.DataFrame(results, columns=['author', 'party', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "\n",
    "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
    "# Note that this may take a bit of time, since we have a lot of tweets.\n",
    "\n",
    "\n",
    "text = []\n",
    "\n",
    "for row in resultsdf[\"text\"]:\n",
    "    try:\n",
    "        text.append(row.decode())\n",
    "    except:\n",
    "        text.append(row.encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>party</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>cleantext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mo Brooks</td>\n",
       "      <td>Republican</td>\n",
       "      <td>\"Brooks Joins Alabama Delegation in Voting Aga...</td>\n",
       "      <td>[brooks, joins, alabama, delegation, voting, f...</td>\n",
       "      <td>brooks joins alabama delegation in voting agai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mo Brooks</td>\n",
       "      <td>Republican</td>\n",
       "      <td>\"Brooks: Senate Democrats Allowing President t...</td>\n",
       "      <td>[brooks, senate, democrats, allowing, presiden...</td>\n",
       "      <td>brooks senate democrats allowing president to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mo Brooks</td>\n",
       "      <td>Republican</td>\n",
       "      <td>\"NASA on the Square\" event this Sat. 11AM – 4P...</td>\n",
       "      <td>[nasa, square, event, sat, 11am, –, 4pm, stop,...</td>\n",
       "      <td>nasa on the square event this sat 11am – 4pm s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mo Brooks</td>\n",
       "      <td>Republican</td>\n",
       "      <td>\"The trouble with Socialism is that eventually...</td>\n",
       "      <td>[trouble, socialism, eventually, run, peoples,...</td>\n",
       "      <td>the trouble with socialism is that eventually ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mo Brooks</td>\n",
       "      <td>Republican</td>\n",
       "      <td>\"The trouble with socialism is eventually you ...</td>\n",
       "      <td>[trouble, socialism, eventually, run, peoples,...</td>\n",
       "      <td>the trouble with socialism is eventually you r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664651</th>\n",
       "      <td>David McKinley</td>\n",
       "      <td>Republican</td>\n",
       "      <td>We had a great time at the WVU Homecoming para...</td>\n",
       "      <td>[great, time, wvu, homecoming, parade, yesterd...</td>\n",
       "      <td>we had a great time at the wvu homecoming para...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664652</th>\n",
       "      <td>David McKinley</td>\n",
       "      <td>Republican</td>\n",
       "      <td>We need more transparency in Washington #wvpol...</td>\n",
       "      <td>[need, transparency, washington, #wvpol, https...</td>\n",
       "      <td>we need more transparency in washington #wvpol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664653</th>\n",
       "      <td>David McKinley</td>\n",
       "      <td>Republican</td>\n",
       "      <td>We saw there is a double standard in DC and th...</td>\n",
       "      <td>[saw, double, standard, dc, rules, simply, don...</td>\n",
       "      <td>we saw there is a double standard in dc and th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664654</th>\n",
       "      <td>David McKinley</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Wow! Huge crowd in Charleston at the @WVGOP vi...</td>\n",
       "      <td>[wow, huge, crowd, charleston, wvgop, victory,...</td>\n",
       "      <td>wow huge crowd in charleston at the wvgop vict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664655</th>\n",
       "      <td>David McKinley</td>\n",
       "      <td>Republican</td>\n",
       "      <td>https://t.co/0QmZlRfEcD https://t.co/FY520NC2GB</td>\n",
       "      <td>[httpstco0qmzlrfecd, httpstcofy520nc2gb]</td>\n",
       "      <td>httpstco0qmzlrfecd httpstcofy520nc2gb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>664656 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                author       party  \\\n",
       "0            Mo Brooks  Republican   \n",
       "1            Mo Brooks  Republican   \n",
       "2            Mo Brooks  Republican   \n",
       "3            Mo Brooks  Republican   \n",
       "4            Mo Brooks  Republican   \n",
       "...                ...         ...   \n",
       "664651  David McKinley  Republican   \n",
       "664652  David McKinley  Republican   \n",
       "664653  David McKinley  Republican   \n",
       "664654  David McKinley  Republican   \n",
       "664655  David McKinley  Republican   \n",
       "\n",
       "                                                     text  \\\n",
       "0       \"Brooks Joins Alabama Delegation in Voting Aga...   \n",
       "1       \"Brooks: Senate Democrats Allowing President t...   \n",
       "2       \"NASA on the Square\" event this Sat. 11AM – 4P...   \n",
       "3       \"The trouble with Socialism is that eventually...   \n",
       "4       \"The trouble with socialism is eventually you ...   \n",
       "...                                                   ...   \n",
       "664651  We had a great time at the WVU Homecoming para...   \n",
       "664652  We need more transparency in Washington #wvpol...   \n",
       "664653  We saw there is a double standard in DC and th...   \n",
       "664654  Wow! Huge crowd in Charleston at the @WVGOP vi...   \n",
       "664655    https://t.co/0QmZlRfEcD https://t.co/FY520NC2GB   \n",
       "\n",
       "                                                   tokens  \\\n",
       "0       [brooks, joins, alabama, delegation, voting, f...   \n",
       "1       [brooks, senate, democrats, allowing, presiden...   \n",
       "2       [nasa, square, event, sat, 11am, –, 4pm, stop,...   \n",
       "3       [trouble, socialism, eventually, run, peoples,...   \n",
       "4       [trouble, socialism, eventually, run, peoples,...   \n",
       "...                                                   ...   \n",
       "664651  [great, time, wvu, homecoming, parade, yesterd...   \n",
       "664652  [need, transparency, washington, #wvpol, https...   \n",
       "664653  [saw, double, standard, dc, rules, simply, don...   \n",
       "664654  [wow, huge, crowd, charleston, wvgop, victory,...   \n",
       "664655           [httpstco0qmzlrfecd, httpstcofy520nc2gb]   \n",
       "\n",
       "                                                cleantext  \n",
       "0       brooks joins alabama delegation in voting agai...  \n",
       "1       brooks senate democrats allowing president to ...  \n",
       "2       nasa on the square event this sat 11am – 4pm s...  \n",
       "3       the trouble with socialism is that eventually ...  \n",
       "4       the trouble with socialism is eventually you r...  \n",
       "...                                                   ...  \n",
       "664651  we had a great time at the wvu homecoming para...  \n",
       "664652  we need more transparency in washington #wvpol...  \n",
       "664653  we saw there is a double standard in dc and th...  \n",
       "664654  wow huge crowd in charleston at the wvgop vict...  \n",
       "664655              httpstco0qmzlrfecd httpstcofy520nc2gb  \n",
       "\n",
       "[664656 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsdf[\"text\"] = text\n",
    "resultsdf[\"tokens\"] = resultsdf[\"text\"].apply(prepare,pipeline=my_pipeline)\n",
    "resultsdf[\"cleantext\"] = resultsdf[\"text\"].apply(clean)\n",
    "resultsdf[\"cleantext\"] = resultsdf[\"cleantext\"].apply(str.lower)\n",
    "resultsdf[\"cleantext\"] = resultsdf[\"cleantext\"].apply(remove_punctuation)\n",
    "resultsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_results = resultsdf[[\"cleantext\", \"party\"]]\n",
    "tweet_data = query_results.values.tolist()\n",
    "#tweet_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 51762 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in tweet_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party)\n",
    "               for (text, party) in tweet_data]\n",
    "tweet_data = featuresets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(tweet_data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: {'earlier': True, 'today': True, 'i': True, 'spoke': True, 'on': True, 'the': True, 'house': True, 'floor': True, 'abt': True, 'protecting': True, 'health': True, 'care': True, 'for': True, 'women': True, 'and': True, 'praised': True, 'their': True, 'work': True, 'central': True, 'coast': True}\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: {'go': True, 'tribe': True, '#rallytogether': True}\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: {'apparently': True, 'trump': True, 'thinks': True, 'its': True, 'just': True, 'too': True, 'easy': True, 'for': True, 'students': True, 'overwhelmed': True, 'by': True, 'the': True, 'crushing': True, 'burden': True, 'of': True, 'debt': True, 'to': True, 'pay': True, 'off': True, 'student': True, 'loans': True, '#trumpbudget': True}\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: {'we’re': True, 'grateful': True, 'for': True, 'our': True, 'first': True, 'responders': True, 'rescue': True, 'personnel': True, 'firefighters': True, 'police': True, 'and': True, 'volunteers': True, 'who': True, 'have': True, 'been': True, 'working': True, 'tirelessly': True, 'to': True, 'keep': True, 'people': True, 'safe': True, 'provide': True, 'muchneeded': True, 'help': True, 'while': True, 'putting': True, 'their': True, 'own': True, 'lives': True, 'on': True, 'the': True, 'line': True}\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: {'let’s': True, 'make': True, 'it': True, 'even': True, 'greater': True, '#kag': True, '🇺🇸': True}\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: {'we': True, 'have': True, 'about': True, 'until': True, 'the': True, 'cavs': True, 'tie': True, 'up': True, 'series': True, '22': True, 'im': True, '#allin216': True, 'repbarbaralee': True, 'you': True, 'scared': True, '#roadtovictory': True}\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: {'congrats': True, 'to': True, 'on': True, 'his': True, 'new': True, 'gig': True, 'at': True, 'sd': True, 'city': True, 'hall': True, 'we': True, 'are': True, 'glad': True, 'you': True, 'will': True, 'continue': True}\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: {'we': True, 'are': True, 'really': True, 'close': True, 'have': True, 'over': True, '3500': True, 'raised': True, 'toward': True, 'the': True, 'match': True, 'right': True, 'now': True, 'that’s': True, '7000': True, 'for': True, 'majors': True, 'in': True, 'room': True, '😂': True, 'help': True, 'us': True, 'get': True, 'there': True}\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: {'today': True, 'the': True, 'comment': True, 'period': True, 'for': True, 'potus’s': True, 'plan': True, 'to': True, 'expand': True, 'offshore': True, 'drilling': True, 'opened': True, 'public': True, 'you': True, 'have': True, '60': True, 'days': True, 'until': True, 'march': True, '9': True, 'share': True, 'why': True, 'oppose': True, 'proposed': True, 'program': True, 'directly': True, 'with': True, 'trump': True, 'administration': True, 'comments': True, 'can': True, 'be': True, 'made': True, 'by': True, 'email': True, 'or': True, 'mail': True}\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: {'celebrated': True, '22': True, 'years': True, 'of': True, 'eastside': True, 'commitment': True, 'saluted': True, 'community': True, 'leaders': True, 'at': True, 'last': True, 'night’s': True, 'awards': True, 'dinner': True}\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for tweet, party in tweet_data_sample :\n",
    "    estimated_party = classifier.classify(tweet)\n",
    "    # Fill in the right-hand side above with code that estimates the actual party\n",
    "    \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48471991526443753\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, tweet_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                     and = True           Republ : Democr =      3.0 : 1.0\n",
      "                    help = True           Republ : Democr =      3.0 : 1.0\n",
      "                   their = True           Republ : Democr =      3.0 : 1.0\n",
      "                    #kag = None           Democr : Republ =      1.9 : 1.0\n",
      "                    been = None           Democr : Republ =      1.9 : 1.0\n",
      "                    even = None           Democr : Republ =      1.9 : 1.0\n",
      "            firefighters = None           Democr : Republ =      1.9 : 1.0\n",
      "                   first = None           Democr : Republ =      1.9 : 1.0\n",
      "                grateful = None           Democr : Republ =      1.9 : 1.0\n",
      "                 greater = None           Democr : Republ =      1.9 : 1.0\n",
      "                      it = None           Democr : Republ =      1.9 : 1.0\n",
      "                    keep = None           Democr : Republ =      1.9 : 1.0\n",
      "                   let’s = None           Democr : Republ =      1.9 : 1.0\n",
      "                    line = None           Democr : Republ =      1.9 : 1.0\n",
      "                   lives = None           Democr : Republ =      1.9 : 1.0\n",
      "                    make = None           Democr : Republ =      1.9 : 1.0\n",
      "              muchneeded = None           Democr : Republ =      1.9 : 1.0\n",
      "                     our = None           Democr : Republ =      1.9 : 1.0\n",
      "                     own = None           Democr : Republ =      1.9 : 1.0\n",
      "                  people = None           Democr : Republ =      1.9 : 1.0\n",
      "               personnel = None           Democr : Republ =      1.9 : 1.0\n",
      "                  police = None           Democr : Republ =      1.9 : 1.0\n",
      "                 provide = None           Democr : Republ =      1.9 : 1.0\n",
      "                 putting = None           Democr : Republ =      1.9 : 1.0\n",
      "                  rescue = None           Democr : Republ =      1.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data) :\n",
    "    tweet, party = tp    \n",
    "    # Now do the same thing as above, but we store the results rather\n",
    "    # than printing them. \n",
    "   \n",
    "    # get the estimated party\n",
    "    estimated_party = classifier.classify(tweet)\n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score : \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'Republican': defaultdict(int,\n",
       "                         {'Republican': 1408, 'Democratic': 2870}),\n",
       "             'Democratic': defaultdict(int,\n",
       "                         {'Republican': 2303, 'Democratic': 3421})})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "With a smaller sample size, the tweet dataset exhibits lower keyword indicativeness compared to congressional data. Although overall accuracy reaches 48.5%, establishing clear party-keyword connections proves challenging. The model's inclination towards Republicans suggests a disparity between political speeches and tweets. The abundance and diversity of tweets, including hashtags and errors, complicate classification. Naive Bayes' independence assumption and the dominance of Republican features may skew results. Refined feature engineering, accounting for the nuances of Twitter discourse, is crucial for improving accuracy in capturing the intricacies of political language on social media."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
